

![Diagramă bloc_v2](https://github.com/user-attachments/assets/90cabb96-57f7-4d50-8aa7-9fea2aefa8bc)
1.	Setul de date
   
	•	VisDrone https://github.com/VisDrone/VisDrone-Dataset

	•	Include imaginile foto-video pe baza cărora vom testa soluția noastră pe tot parcursul dezvoltării.

3.	Preprocesare
	•	Îmbunătățirea imaginilor pentru a asigura acuratețea rezultatelor și ușurința recunoașterii obiectelor;
	•	Aceasta presupune, în funcție de calitatea datelor, și nevoi îmbunătățirea contrastului, aplicarea de filtre pentru a elimina/limita blurarea imaginilor cauzată de mișcare sau evidențierea detaliilor.

4.	Detectarea obiectelor
	
	•	Vom folosi OpenCV, TensorFlow, YOLO pentru a detecta prezența obiectelor de interes (ex. autovehicule, clădiri, obstacole).

5.	Recunoașterea obiectelor

	•	Se folosesc resursele de mai sus, însă cu scopul de a diferenția și clasifica obiectele extrase din cadre (de exemplu folosind funcții din OpenCV).

6.	Urmărire (tracking)
	
	•	Avem la dispoziție mai multe opțiuni. De exemplu, Open CV oferă algoritmi cum ar fi KLT sau Optical Flow.



| Nr. | Autor(i)/An | Titlul articolului/ proiectului | Aplicație/ Domeniu | Tehnologii utilizate | Metodologie/ Abordare | Rezultate | Limitări | Comentarii suplimentare |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| 1\. | Pengfei Zhu, Longyin Wen, Dawei Du, Xiao Bian, Heng Fan, Qinghua Hu, Haibin Ling/2022 | Detection and Tracking Meet Drones Challenge | AI/Deep learning | YOLOv3, rețele neuronale convolutive | Multi object tracking,Joint tracking and detection approach, Multi-scale representation, Onmi-scale representation,ReID representation,Multiple granularity representation   | Multiple object tracking accuracy (MOTA) \=42.6%, false negatives (FN)=62819, false positives (FP)=5445, ID switches(IDs)=265  | Legate de calitatea imaginilor din drone: motion blur, perspectiva în continuă schimbare, mișcări bruște | For each object instance it successfully locates in an image, a Framework for object instance segmentation method simultaneously builds a top-notch segmentation mask. Combining the existing branch for bounding box recognition with the fresh branch for object mask prediction  |
| 2\. | Jehwan Choi; Seongbo Ha; Youlkyeong Lee; Kanghyun Jo/2023 | Vehicle Tracking System in Drone Imagery with YOLOv5 and Histogram  | AI/Deep learning | OpenCV | Since the size and aspect ratio of objects are different, different areas may occur in the image.Once the object is found, feature extraction is performed to provide a robust representation.  | Multiple object tracking accuracy (MOTA) \=90%, false negatives (FN)=401, false positives (FP)=1, ID switches(IDs)=28, and GT (Ground Truth)=4036 | Acuratețea coordonatelor generate de model nu este constantă Instabilitatea dronei  | Unsupervised object detection: Automated labeling technology is exciting and promising. Unsupervised object detection can eliminate manual labeling. |
| 3\. | [Karam M. Abughalieh](https://link.springer.com/article/10.1007/s11042-018-6508-1#auth-Karam_M_-Abughalieh-Aff1),  [Belal H. Sababha](https://link.springer.com/article/10.1007/s11042-018-6508-1#auth-Belal_H_-Sababha-Aff1) &  [Nathir A. Rawashdeh](https://link.springer.com/article/10.1007/s11042-018-6508-1#auth-Nathir_A_-Rawashdeh-Aff2)   | Object detection and tracking system for weight sensitive UAVs | AI/Deep learning | OpenCV | The proposed system is intended for UAV applications capturing long range aerial video. Challenges of working with aerial long range videos include wide scene views, high noise, low detection rates of features, and camera motion due to the UAV movement. In addition, the system is required to perform in real-time with low power and memory resources.  | The results show that SURF finished the task of extracting keypoints five times faster (i.e. working on the 25% size mask), while SIFT finished 1.6 times faster. FAST has done the task 15 times faster. | Este folosit un procentaj aproximat intre 25% si 50% din masca pentru recunoasterea si diferentierea obiectelor. Micile detalii nu vor fi recunoste. | In addition, the OpenCV libraries for SIFT, SURF and FAST algorithms were adopted.  |
| 4\. |   **Hyun-Ki Jung Gi-Sang Choi** | Improved YOLOv5: Efficient Object Detection Using Drone Images under Various Conditions  | AI/Deep learning | YOLOv5 | Currently, there are two types of detection methods based on deep learning: 1-stage detector and 2-stage detector. Firstly, 2-stage detector in which regional proposal and classification are performed sequentially. In contrast to 2-stage detector, in the 1-stage detector, a regional proposal and classification are performed simultaneously. In other words, it is a method of solving classification and localization problems at the same time. | We compared based on the best of the 100 epochs result values. In order to objectively evaluate the performance of the models, the values of mAP (Mean average precision) were compared. The mAP value of the original YOLOv5 model is 94.6%, and YOLOv5\_Ours is 95.5%. Overall, it may be seen that the YOLOv5\_Ours model has higher than the original YOLOv5 model. | The function loss difference between the two models results in a large gap at the beginning of the training. Therefore, the experiment was conducted by setting the epoch to 100\. It can be seen that YOLOv5 function loss occurs rapidly at the beginning of training. On the other hand, YOLOv5\_Ours decreased function loss slowly. The gap appears to be narrowing until the epoch reaches 60  | For accurate verification of the study, it is necessary to compare performance with previous YOLO models. Therefore, we decided to experiment by applying the dataset to YOLOv3 and YOLOv4 model. The value of mAP was compared with the previous models: YOLOv3 and YOLOv4 model, and all the experiments were conducted independently |
| 5\. | Chao Chen
Hongrui Min Yi Peng Yongkui Yang Zheng Wang | An Intelligent Real-Time Object Detection System on Drones  | AI/Deep learning | Yolov2 | With the rapid development of technology, researchers have investigated various methods to build intelligent systems and we introduce some typical intelligent systems in this section. Many sensors are equipped in various systems to help gather surrounding information that can be used to make intelligent decisions. Tactile sensors are used in advanced intelligent systems–such as robotics and human-machine interfaces–to achieve safe and precise operations in uncertain environments | We perform object detection and display some detection results in this section. We aim to find the targets of interest in an area using the drone and report detected objects in real time. Note that due to the characteristics of the Yolo model, it is inevitable to produce wrong object detection results. | The object detection speed of our design is only 8 FPS, which is a disadvantage compared to other approaches. This is because our design is limited by the I/O property of the FPGA board, which is an inherent limitation, as indicated by the roofline model. We can improve the speed by using an FPGA board with a high I/O bandwidth in future designs. | It is worth mentioning that since our system can run various neural network models and signal processing tasks, the system is not limited to person and car detection and it can also be used for other object detection or even other types of tasks. |

